2020-07-25 20:47:26.600 | ERROR    | proxypool.crawlers.base:crawl:27 - An error has been caught in function 'crawl', process 'Process-2' (15084), thread 'MainThread' (1308):
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "D:\development\Python\lib\multiprocessing\spawn.py", line 105, in spawn_main
    exitcode = _main(fd)
               ©¦     ©¸ 3
               ©¸ <function _main at 0x000001C03A9DB840>
  File "D:\development\Python\lib\multiprocessing\spawn.py", line 118, in _main
    return self._bootstrap()
           ©¦    ©¸ <function BaseProcess._bootstrap at 0x000001C03A9C78C8>
           ©¸ <Process(Process-2, started)>
  File "D:\development\Python\lib\multiprocessing\process.py", line 258, in _bootstrap
    self.run()
    ©¦    ©¸ <function BaseProcess.run at 0x000001C03A9C70D0>
    ©¸ <Process(Process-2, started)>
  File "D:\development\Python\lib\multiprocessing\process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
    ©¦    ©¦        ©¦    ©¦        ©¦    ©¸ {}
    ©¦    ©¦        ©¦    ©¦        ©¸ <Process(Process-2, started)>
    ©¦    ©¦        ©¦    ©¸ ()
    ©¦    ©¦        ©¸ <Process(Process-2, started)>
    ©¦    ©¸ <bound method Scheduler.run_getter of <proxypool.scheduler.Scheduler object at 0x000001C03CAAE048>>
    ©¸ <Process(Process-2, started)>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\scheduler.py", line 47, in run_getter
    getter.run()
    ©¦      ©¸ <function Getter.run at 0x000001C03C706158>
    ©¸ <proxypool.processors.getter.Getter object at 0x000001C03A9C0DA0>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\processors\getter.py", line 36, in run
    for proxy in crawler.crawl():
                 ©¦       ©¸ <function BaseCrawler.crawl at 0x000001C03C5F76A8>
                 ©¸ <public.66ip.SixIp object at 0x000001C03CAAE2B0>

> File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\crawlers\base.py", line 27, in crawl
    for proxy in self.parse(html):
                 ©¦    ©¦     ©¸ '\r\n<!doctype html public "-//w3c//dtd xhtml 1.0 transitional//en" "http://www.w3.org/tr/xhtml1/dtd/xhtml1-transitional.dtd"...
                 ©¦    ©¸ <function SixIp.parse at 0x000001C03C700D90>
                 ©¸ <public.66ip.SixIp object at 0x000001C03CAAE2B0>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\crawlers\public\66ip.py", line 19, in parse
    port = int(tr.find('td:nth-child(2)').text())
               ©¦  ©¸ <function PyQuery.find at 0x000001C03C6FAD08>
               ©¸ [<table>]

ValueError: invalid literal for int() with base 10: '¶Ë¿ÚºÅ 3128 999 9999 33729 9999 9999 31264 8080 42670 8080 9999'
2020-07-25 20:47:27.170 | ERROR    | proxypool.crawlers.base:crawl:27 - An error has been caught in function 'crawl', process 'Process-2' (15084), thread 'MainThread' (1308):
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "D:\development\Python\lib\multiprocessing\spawn.py", line 105, in spawn_main
    exitcode = _main(fd)
               ©¦     ©¸ 3
               ©¸ <function _main at 0x000001C03A9DB840>
  File "D:\development\Python\lib\multiprocessing\spawn.py", line 118, in _main
    return self._bootstrap()
           ©¦    ©¸ <function BaseProcess._bootstrap at 0x000001C03A9C78C8>
           ©¸ <Process(Process-2, started)>
  File "D:\development\Python\lib\multiprocessing\process.py", line 258, in _bootstrap
    self.run()
    ©¦    ©¸ <function BaseProcess.run at 0x000001C03A9C70D0>
    ©¸ <Process(Process-2, started)>
  File "D:\development\Python\lib\multiprocessing\process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
    ©¦    ©¦        ©¦    ©¦        ©¦    ©¸ {}
    ©¦    ©¦        ©¦    ©¦        ©¸ <Process(Process-2, started)>
    ©¦    ©¦        ©¦    ©¸ ()
    ©¦    ©¦        ©¸ <Process(Process-2, started)>
    ©¦    ©¸ <bound method Scheduler.run_getter of <proxypool.scheduler.Scheduler object at 0x000001C03CAAE048>>
    ©¸ <Process(Process-2, started)>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\scheduler.py", line 47, in run_getter
    getter.run()
    ©¦      ©¸ <function Getter.run at 0x000001C03C706158>
    ©¸ <proxypool.processors.getter.Getter object at 0x000001C03A9C0DA0>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\processors\getter.py", line 36, in run
    for proxy in crawler.crawl():
                 ©¦       ©¸ <function BaseCrawler.crawl at 0x000001C03C5F76A8>
                 ©¸ <public.66ip.SixIp object at 0x000001C03CAAE2B0>

> File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\crawlers\base.py", line 27, in crawl
    for proxy in self.parse(html):
                 ©¦    ©¦     ©¸ '\r\n<!doctype html public "-//w3c//dtd xhtml 1.0 transitional//en" "http://www.w3.org/tr/xhtml1/dtd/xhtml1-transitional.dtd"...
                 ©¦    ©¸ <function SixIp.parse at 0x000001C03C700D90>
                 ©¸ <public.66ip.SixIp object at 0x000001C03CAAE2B0>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\crawlers\public\66ip.py", line 19, in parse
    port = int(tr.find('td:nth-child(2)').text())
               ©¦  ©¸ <function PyQuery.find at 0x000001C03C6FAD08>
               ©¸ [<table>]

ValueError: invalid literal for int() with base 10: '¶Ë¿ÚºÅ 3128 999 9999 33729 9999 9999 31264 8080 42670 8080 9999'
2020-07-25 20:47:27.451 | ERROR    | proxypool.crawlers.base:crawl:27 - An error has been caught in function 'crawl', process 'Process-2' (15084), thread 'MainThread' (1308):
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "D:\development\Python\lib\multiprocessing\spawn.py", line 105, in spawn_main
    exitcode = _main(fd)
               ©¦     ©¸ 3
               ©¸ <function _main at 0x000001C03A9DB840>
  File "D:\development\Python\lib\multiprocessing\spawn.py", line 118, in _main
    return self._bootstrap()
           ©¦    ©¸ <function BaseProcess._bootstrap at 0x000001C03A9C78C8>
           ©¸ <Process(Process-2, started)>
  File "D:\development\Python\lib\multiprocessing\process.py", line 258, in _bootstrap
    self.run()
    ©¦    ©¸ <function BaseProcess.run at 0x000001C03A9C70D0>
    ©¸ <Process(Process-2, started)>
  File "D:\development\Python\lib\multiprocessing\process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
    ©¦    ©¦        ©¦    ©¦        ©¦    ©¸ {}
    ©¦    ©¦        ©¦    ©¦        ©¸ <Process(Process-2, started)>
    ©¦    ©¦        ©¦    ©¸ ()
    ©¦    ©¦        ©¸ <Process(Process-2, started)>
    ©¦    ©¸ <bound method Scheduler.run_getter of <proxypool.scheduler.Scheduler object at 0x000001C03CAAE048>>
    ©¸ <Process(Process-2, started)>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\scheduler.py", line 47, in run_getter
    getter.run()
    ©¦      ©¸ <function Getter.run at 0x000001C03C706158>
    ©¸ <proxypool.processors.getter.Getter object at 0x000001C03A9C0DA0>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\processors\getter.py", line 36, in run
    for proxy in crawler.crawl():
                 ©¦       ©¸ <function BaseCrawler.crawl at 0x000001C03C5F76A8>
                 ©¸ <public.66ip.SixIp object at 0x000001C03CAAE2B0>

> File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\crawlers\base.py", line 27, in crawl
    for proxy in self.parse(html):
                 ©¦    ©¦     ©¸ '\r\n<!doctype html public "-//w3c//dtd xhtml 1.0 transitional//en" "http://www.w3.org/tr/xhtml1/dtd/xhtml1-transitional.dtd"...
                 ©¦    ©¸ <function SixIp.parse at 0x000001C03C700D90>
                 ©¸ <public.66ip.SixIp object at 0x000001C03CAAE2B0>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\crawlers\public\66ip.py", line 19, in parse
    port = int(tr.find('td:nth-child(2)').text())
               ©¦  ©¸ <function PyQuery.find at 0x000001C03C6FAD08>
               ©¸ [<table>]

ValueError: invalid literal for int() with base 10: '¶Ë¿ÚºÅ 3128 36910 8118 8080 61815 9999 5836 8080 5836 8080 8080 8811'
2020-07-25 20:47:27.738 | ERROR    | proxypool.crawlers.base:crawl:27 - An error has been caught in function 'crawl', process 'Process-2' (15084), thread 'MainThread' (1308):
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "D:\development\Python\lib\multiprocessing\spawn.py", line 105, in spawn_main
    exitcode = _main(fd)
               ©¦     ©¸ 3
               ©¸ <function _main at 0x000001C03A9DB840>
  File "D:\development\Python\lib\multiprocessing\spawn.py", line 118, in _main
    return self._bootstrap()
           ©¦    ©¸ <function BaseProcess._bootstrap at 0x000001C03A9C78C8>
           ©¸ <Process(Process-2, started)>
  File "D:\development\Python\lib\multiprocessing\process.py", line 258, in _bootstrap
    self.run()
    ©¦    ©¸ <function BaseProcess.run at 0x000001C03A9C70D0>
    ©¸ <Process(Process-2, started)>
  File "D:\development\Python\lib\multiprocessing\process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
    ©¦    ©¦        ©¦    ©¦        ©¦    ©¸ {}
    ©¦    ©¦        ©¦    ©¦        ©¸ <Process(Process-2, started)>
    ©¦    ©¦        ©¦    ©¸ ()
    ©¦    ©¦        ©¸ <Process(Process-2, started)>
    ©¦    ©¸ <bound method Scheduler.run_getter of <proxypool.scheduler.Scheduler object at 0x000001C03CAAE048>>
    ©¸ <Process(Process-2, started)>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\scheduler.py", line 47, in run_getter
    getter.run()
    ©¦      ©¸ <function Getter.run at 0x000001C03C706158>
    ©¸ <proxypool.processors.getter.Getter object at 0x000001C03A9C0DA0>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\processors\getter.py", line 36, in run
    for proxy in crawler.crawl():
                 ©¦       ©¸ <function BaseCrawler.crawl at 0x000001C03C5F76A8>
                 ©¸ <public.66ip.SixIp object at 0x000001C03CAAE2B0>

> File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\crawlers\base.py", line 27, in crawl
    for proxy in self.parse(html):
                 ©¦    ©¦     ©¸ '\r\n<!doctype html public "-//w3c//dtd xhtml 1.0 transitional//en" "http://www.w3.org/tr/xhtml1/dtd/xhtml1-transitional.dtd"...
                 ©¦    ©¸ <function SixIp.parse at 0x000001C03C700D90>
                 ©¸ <public.66ip.SixIp object at 0x000001C03CAAE2B0>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\crawlers\public\66ip.py", line 19, in parse
    port = int(tr.find('td:nth-child(2)').text())
               ©¦  ©¸ <function PyQuery.find at 0x000001C03C6FAD08>
               ©¸ [<table>]

ValueError: invalid literal for int() with base 10: '¶Ë¿ÚºÅ 9999 9999 18759 8888 40049 9999 5836 8080 3128 60619 38011 8080'
2020-07-25 20:47:27.997 | ERROR    | proxypool.crawlers.base:crawl:27 - An error has been caught in function 'crawl', process 'Process-2' (15084), thread 'MainThread' (1308):
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "D:\development\Python\lib\multiprocessing\spawn.py", line 105, in spawn_main
    exitcode = _main(fd)
               ©¦     ©¸ 3
               ©¸ <function _main at 0x000001C03A9DB840>
  File "D:\development\Python\lib\multiprocessing\spawn.py", line 118, in _main
    return self._bootstrap()
           ©¦    ©¸ <function BaseProcess._bootstrap at 0x000001C03A9C78C8>
           ©¸ <Process(Process-2, started)>
  File "D:\development\Python\lib\multiprocessing\process.py", line 258, in _bootstrap
    self.run()
    ©¦    ©¸ <function BaseProcess.run at 0x000001C03A9C70D0>
    ©¸ <Process(Process-2, started)>
  File "D:\development\Python\lib\multiprocessing\process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
    ©¦    ©¦        ©¦    ©¦        ©¦    ©¸ {}
    ©¦    ©¦        ©¦    ©¦        ©¸ <Process(Process-2, started)>
    ©¦    ©¦        ©¦    ©¸ ()
    ©¦    ©¦        ©¸ <Process(Process-2, started)>
    ©¦    ©¸ <bound method Scheduler.run_getter of <proxypool.scheduler.Scheduler object at 0x000001C03CAAE048>>
    ©¸ <Process(Process-2, started)>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\scheduler.py", line 47, in run_getter
    getter.run()
    ©¦      ©¸ <function Getter.run at 0x000001C03C706158>
    ©¸ <proxypool.processors.getter.Getter object at 0x000001C03A9C0DA0>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\processors\getter.py", line 36, in run
    for proxy in crawler.crawl():
                 ©¦       ©¸ <function BaseCrawler.crawl at 0x000001C03C5F76A8>
                 ©¸ <public.66ip.SixIp object at 0x000001C03CAAE2B0>

> File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\crawlers\base.py", line 27, in crawl
    for proxy in self.parse(html):
                 ©¦    ©¦     ©¸ '\r\n<!doctype html public "-//w3c//dtd xhtml 1.0 transitional//en" "http://www.w3.org/tr/xhtml1/dtd/xhtml1-transitional.dtd"...
                 ©¦    ©¸ <function SixIp.parse at 0x000001C03C700D90>
                 ©¸ <public.66ip.SixIp object at 0x000001C03CAAE2B0>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\crawlers\public\66ip.py", line 19, in parse
    port = int(tr.find('td:nth-child(2)').text())
               ©¦  ©¸ <function PyQuery.find at 0x000001C03C6FAD08>
               ©¸ [<table>]

ValueError: invalid literal for int() with base 10: '¶Ë¿ÚºÅ 9999 5836 8080 34235 80 9999 8080 8123 8080 35101 8080 61574'
2020-07-25 20:47:28.240 | ERROR    | proxypool.crawlers.base:crawl:27 - An error has been caught in function 'crawl', process 'Process-2' (15084), thread 'MainThread' (1308):
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "D:\development\Python\lib\multiprocessing\spawn.py", line 105, in spawn_main
    exitcode = _main(fd)
               ©¦     ©¸ 3
               ©¸ <function _main at 0x000001C03A9DB840>
  File "D:\development\Python\lib\multiprocessing\spawn.py", line 118, in _main
    return self._bootstrap()
           ©¦    ©¸ <function BaseProcess._bootstrap at 0x000001C03A9C78C8>
           ©¸ <Process(Process-2, started)>
  File "D:\development\Python\lib\multiprocessing\process.py", line 258, in _bootstrap
    self.run()
    ©¦    ©¸ <function BaseProcess.run at 0x000001C03A9C70D0>
    ©¸ <Process(Process-2, started)>
  File "D:\development\Python\lib\multiprocessing\process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
    ©¦    ©¦        ©¦    ©¦        ©¦    ©¸ {}
    ©¦    ©¦        ©¦    ©¦        ©¸ <Process(Process-2, started)>
    ©¦    ©¦        ©¦    ©¸ ()
    ©¦    ©¦        ©¸ <Process(Process-2, started)>
    ©¦    ©¸ <bound method Scheduler.run_getter of <proxypool.scheduler.Scheduler object at 0x000001C03CAAE048>>
    ©¸ <Process(Process-2, started)>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\scheduler.py", line 47, in run_getter
    getter.run()
    ©¦      ©¸ <function Getter.run at 0x000001C03C706158>
    ©¸ <proxypool.processors.getter.Getter object at 0x000001C03A9C0DA0>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\processors\getter.py", line 36, in run
    for proxy in crawler.crawl():
                 ©¦       ©¸ <function BaseCrawler.crawl at 0x000001C03C5F76A8>
                 ©¸ <public.66ip.SixIp object at 0x000001C03CAAE2B0>

> File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\crawlers\base.py", line 27, in crawl
    for proxy in self.parse(html):
                 ©¦    ©¦     ©¸ '\r\n<!doctype html public "-//w3c//dtd xhtml 1.0 transitional//en" "http://www.w3.org/tr/xhtml1/dtd/xhtml1-transitional.dtd"...
                 ©¦    ©¸ <function SixIp.parse at 0x000001C03C700D90>
                 ©¸ <public.66ip.SixIp object at 0x000001C03CAAE2B0>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\crawlers\public\66ip.py", line 19, in parse
    port = int(tr.find('td:nth-child(2)').text())
               ©¦  ©¸ <function PyQuery.find at 0x000001C03C6FAD08>
               ©¸ [<table>]

ValueError: invalid literal for int() with base 10: '¶Ë¿ÚºÅ 44975 3128 9999 5836 9999 3128 999 8080 8080 9999 3128 8080'
2020-07-25 20:47:28.479 | ERROR    | proxypool.crawlers.base:crawl:27 - An error has been caught in function 'crawl', process 'Process-2' (15084), thread 'MainThread' (1308):
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "D:\development\Python\lib\multiprocessing\spawn.py", line 105, in spawn_main
    exitcode = _main(fd)
               ©¦     ©¸ 3
               ©¸ <function _main at 0x000001C03A9DB840>
  File "D:\development\Python\lib\multiprocessing\spawn.py", line 118, in _main
    return self._bootstrap()
           ©¦    ©¸ <function BaseProcess._bootstrap at 0x000001C03A9C78C8>
           ©¸ <Process(Process-2, started)>
  File "D:\development\Python\lib\multiprocessing\process.py", line 258, in _bootstrap
    self.run()
    ©¦    ©¸ <function BaseProcess.run at 0x000001C03A9C70D0>
    ©¸ <Process(Process-2, started)>
  File "D:\development\Python\lib\multiprocessing\process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
    ©¦    ©¦        ©¦    ©¦        ©¦    ©¸ {}
    ©¦    ©¦        ©¦    ©¦        ©¸ <Process(Process-2, started)>
    ©¦    ©¦        ©¦    ©¸ ()
    ©¦    ©¦        ©¸ <Process(Process-2, started)>
    ©¦    ©¸ <bound method Scheduler.run_getter of <proxypool.scheduler.Scheduler object at 0x000001C03CAAE048>>
    ©¸ <Process(Process-2, started)>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\scheduler.py", line 47, in run_getter
    getter.run()
    ©¦      ©¸ <function Getter.run at 0x000001C03C706158>
    ©¸ <proxypool.processors.getter.Getter object at 0x000001C03A9C0DA0>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\processors\getter.py", line 36, in run
    for proxy in crawler.crawl():
                 ©¦       ©¸ <function BaseCrawler.crawl at 0x000001C03C5F76A8>
                 ©¸ <public.66ip.SixIp object at 0x000001C03CAAE2B0>

> File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\crawlers\base.py", line 27, in crawl
    for proxy in self.parse(html):
                 ©¦    ©¦     ©¸ '\r\n<!doctype html public "-//w3c//dtd xhtml 1.0 transitional//en" "http://www.w3.org/tr/xhtml1/dtd/xhtml1-transitional.dtd"...
                 ©¦    ©¸ <function SixIp.parse at 0x000001C03C700D90>
                 ©¸ <public.66ip.SixIp object at 0x000001C03CAAE2B0>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\crawlers\public\66ip.py", line 19, in parse
    port = int(tr.find('td:nth-child(2)').text())
               ©¦  ©¸ <function PyQuery.find at 0x000001C03C6FAD08>
               ©¸ [<table>]

ValueError: invalid literal for int() with base 10: '¶Ë¿ÚºÅ 9000 9999 8899 8080 9999 8080 999 44939 9999 20096 53281 8080'
2020-07-25 20:47:28.729 | ERROR    | proxypool.crawlers.base:crawl:27 - An error has been caught in function 'crawl', process 'Process-2' (15084), thread 'MainThread' (1308):
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "D:\development\Python\lib\multiprocessing\spawn.py", line 105, in spawn_main
    exitcode = _main(fd)
               ©¦     ©¸ 3
               ©¸ <function _main at 0x000001C03A9DB840>
  File "D:\development\Python\lib\multiprocessing\spawn.py", line 118, in _main
    return self._bootstrap()
           ©¦    ©¸ <function BaseProcess._bootstrap at 0x000001C03A9C78C8>
           ©¸ <Process(Process-2, started)>
  File "D:\development\Python\lib\multiprocessing\process.py", line 258, in _bootstrap
    self.run()
    ©¦    ©¸ <function BaseProcess.run at 0x000001C03A9C70D0>
    ©¸ <Process(Process-2, started)>
  File "D:\development\Python\lib\multiprocessing\process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
    ©¦    ©¦        ©¦    ©¦        ©¦    ©¸ {}
    ©¦    ©¦        ©¦    ©¦        ©¸ <Process(Process-2, started)>
    ©¦    ©¦        ©¦    ©¸ ()
    ©¦    ©¦        ©¸ <Process(Process-2, started)>
    ©¦    ©¸ <bound method Scheduler.run_getter of <proxypool.scheduler.Scheduler object at 0x000001C03CAAE048>>
    ©¸ <Process(Process-2, started)>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\scheduler.py", line 47, in run_getter
    getter.run()
    ©¦      ©¸ <function Getter.run at 0x000001C03C706158>
    ©¸ <proxypool.processors.getter.Getter object at 0x000001C03A9C0DA0>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\processors\getter.py", line 36, in run
    for proxy in crawler.crawl():
                 ©¦       ©¸ <function BaseCrawler.crawl at 0x000001C03C5F76A8>
                 ©¸ <public.66ip.SixIp object at 0x000001C03CAAE2B0>

> File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\crawlers\base.py", line 27, in crawl
    for proxy in self.parse(html):
                 ©¦    ©¦     ©¸ '\r\n<!doctype html public "-//w3c//dtd xhtml 1.0 transitional//en" "http://www.w3.org/tr/xhtml1/dtd/xhtml1-transitional.dtd"...
                 ©¦    ©¸ <function SixIp.parse at 0x000001C03C700D90>
                 ©¸ <public.66ip.SixIp object at 0x000001C03CAAE2B0>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\crawlers\public\66ip.py", line 19, in parse
    port = int(tr.find('td:nth-child(2)').text())
               ©¦  ©¸ <function PyQuery.find at 0x000001C03C6FAD08>
               ©¸ [<table>]

ValueError: invalid literal for int() with base 10: '¶Ë¿ÚºÅ 9999 5836 8080 36609 55138 8080 9999 8080 999 47687 5836 9991'
2020-07-25 20:47:28.965 | ERROR    | proxypool.crawlers.base:crawl:27 - An error has been caught in function 'crawl', process 'Process-2' (15084), thread 'MainThread' (1308):
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "D:\development\Python\lib\multiprocessing\spawn.py", line 105, in spawn_main
    exitcode = _main(fd)
               ©¦     ©¸ 3
               ©¸ <function _main at 0x000001C03A9DB840>
  File "D:\development\Python\lib\multiprocessing\spawn.py", line 118, in _main
    return self._bootstrap()
           ©¦    ©¸ <function BaseProcess._bootstrap at 0x000001C03A9C78C8>
           ©¸ <Process(Process-2, started)>
  File "D:\development\Python\lib\multiprocessing\process.py", line 258, in _bootstrap
    self.run()
    ©¦    ©¸ <function BaseProcess.run at 0x000001C03A9C70D0>
    ©¸ <Process(Process-2, started)>
  File "D:\development\Python\lib\multiprocessing\process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
    ©¦    ©¦        ©¦    ©¦        ©¦    ©¸ {}
    ©¦    ©¦        ©¦    ©¦        ©¸ <Process(Process-2, started)>
    ©¦    ©¦        ©¦    ©¸ ()
    ©¦    ©¦        ©¸ <Process(Process-2, started)>
    ©¦    ©¸ <bound method Scheduler.run_getter of <proxypool.scheduler.Scheduler object at 0x000001C03CAAE048>>
    ©¸ <Process(Process-2, started)>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\scheduler.py", line 47, in run_getter
    getter.run()
    ©¦      ©¸ <function Getter.run at 0x000001C03C706158>
    ©¸ <proxypool.processors.getter.Getter object at 0x000001C03A9C0DA0>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\processors\getter.py", line 36, in run
    for proxy in crawler.crawl():
                 ©¦       ©¸ <function BaseCrawler.crawl at 0x000001C03C5F76A8>
                 ©¸ <public.66ip.SixIp object at 0x000001C03CAAE2B0>

> File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\crawlers\base.py", line 27, in crawl
    for proxy in self.parse(html):
                 ©¦    ©¦     ©¸ '\r\n<!doctype html public "-//w3c//dtd xhtml 1.0 transitional//en" "http://www.w3.org/tr/xhtml1/dtd/xhtml1-transitional.dtd"...
                 ©¦    ©¸ <function SixIp.parse at 0x000001C03C700D90>
                 ©¸ <public.66ip.SixIp object at 0x000001C03CAAE2B0>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\crawlers\public\66ip.py", line 19, in parse
    port = int(tr.find('td:nth-child(2)').text())
               ©¦  ©¸ <function PyQuery.find at 0x000001C03C6FAD08>
               ©¸ [<table>]

ValueError: invalid literal for int() with base 10: '¶Ë¿ÚºÅ 80 5836 3129 8080 9999 8080 5836 80 20018 53117 8080 23500'
2020-07-25 20:47:36.575 | ERROR    | proxypool.processors.getter:run:36 - An error has been caught in function 'run', process 'Process-2' (15084), thread 'MainThread' (1308):
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "D:\development\Python\lib\multiprocessing\spawn.py", line 105, in spawn_main
    exitcode = _main(fd)
               ©¦     ©¸ 3
               ©¸ <function _main at 0x000001C03A9DB840>
  File "D:\development\Python\lib\multiprocessing\spawn.py", line 118, in _main
    return self._bootstrap()
           ©¦    ©¸ <function BaseProcess._bootstrap at 0x000001C03A9C78C8>
           ©¸ <Process(Process-2, started)>
  File "D:\development\Python\lib\multiprocessing\process.py", line 258, in _bootstrap
    self.run()
    ©¦    ©¸ <function BaseProcess.run at 0x000001C03A9C70D0>
    ©¸ <Process(Process-2, started)>
  File "D:\development\Python\lib\multiprocessing\process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
    ©¦    ©¦        ©¦    ©¦        ©¦    ©¸ {}
    ©¦    ©¦        ©¦    ©¦        ©¸ <Process(Process-2, started)>
    ©¦    ©¦        ©¦    ©¸ ()
    ©¦    ©¦        ©¸ <Process(Process-2, started)>
    ©¦    ©¸ <bound method Scheduler.run_getter of <proxypool.scheduler.Scheduler object at 0x000001C03CAAE048>>
    ©¸ <Process(Process-2, started)>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\scheduler.py", line 47, in run_getter
    getter.run()
    ©¦      ©¸ <function Getter.run at 0x000001C03C706158>
    ©¸ <proxypool.processors.getter.Getter object at 0x000001C03A9C0DA0>

> File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\processors\getter.py", line 36, in run
    for proxy in crawler.crawl():
        ©¦        ©¦       ©¸ <function BaseCrawler.crawl at 0x000001C03C5F76A8>
        ©¦        ©¸ <public.kuaidaili.KuaidailiCrawler object at 0x000001C03CAAE240>
        ©¸ Proxy(host='117.85.48.26', port='9999')

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\crawlers\base.py", line 26, in crawl
    html = self.fetch(url)
    ©¦      ©¦    ©¦     ©¸ 'https://www.kuaidaili.com/free/inha/2/'
    ©¦      ©¦    ©¸ <function BaseCrawler.fetch at 0x000001C03C5F7620>
    ©¦      ©¸ <public.kuaidaili.KuaidailiCrawler object at 0x000001C03CAAE240>
    ©¸ '<!DOCTYPE html>\n<html>\n<head>\n<meta http-equiv="X-UA-Compatible" content="IE=edge" />\n<meta http-equiv="Content-Type" co...

  File "D:\development\Python\lib\site-packages\retrying.py", line 49, in wrapped_f
    return Retrying(*dargs, **dkw).call(f, *args, **kw)
           ©¦         ©¦        ©¦         ©¦   ©¦       ©¸ {}
           ©¦         ©¦        ©¦         ©¦   ©¸ (<public.kuaidaili.KuaidailiCrawler object at 0x000001C03CAAE240>, 'https://www.kuaidaili.com/free/inha/2/')
           ©¦         ©¦        ©¦         ©¸ <function BaseCrawler.fetch at 0x000001C03C5F7598>
           ©¦         ©¦        ©¸ {'stop_max_attempt_number': 3, 'retry_on_result': <function BaseCrawler.<lambda> at 0x000001C03C109EA0>}
           ©¦         ©¸ ()
           ©¸ <class 'retrying.Retrying'>
  File "D:\development\Python\lib\site-packages\retrying.py", line 214, in call
    raise RetryError(attempt)
          ©¦          ©¸ Attempts: 3, Value: None
          ©¸ <class 'retrying.RetryError'>

retrying.RetryError: RetryError[Attempts: 3, Value: None]
2020-07-25 20:48:14.482 | ERROR    | proxypool.crawlers.base:crawl:27 - An error has been caught in function 'crawl', process 'Process-2' (2256), thread 'MainThread' (11944):
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "D:\development\Python\lib\multiprocessing\spawn.py", line 105, in spawn_main
    exitcode = _main(fd)
               ©¦     ©¸ 3
               ©¸ <function _main at 0x000001F4DC1AB840>
  File "D:\development\Python\lib\multiprocessing\spawn.py", line 118, in _main
    return self._bootstrap()
           ©¦    ©¸ <function BaseProcess._bootstrap at 0x000001F4DC1968C8>
           ©¸ <Process(Process-2, started)>
  File "D:\development\Python\lib\multiprocessing\process.py", line 258, in _bootstrap
    self.run()
    ©¦    ©¸ <function BaseProcess.run at 0x000001F4DC1960D0>
    ©¸ <Process(Process-2, started)>
  File "D:\development\Python\lib\multiprocessing\process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
    ©¦    ©¦        ©¦    ©¦        ©¦    ©¸ {}
    ©¦    ©¦        ©¦    ©¦        ©¸ <Process(Process-2, started)>
    ©¦    ©¦        ©¦    ©¸ ()
    ©¦    ©¦        ©¸ <Process(Process-2, started)>
    ©¦    ©¸ <bound method Scheduler.run_getter of <proxypool.scheduler.Scheduler object at 0x000001F4DE27E048>>
    ©¸ <Process(Process-2, started)>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\scheduler.py", line 47, in run_getter
    getter.run()
    ©¦      ©¸ <function Getter.run at 0x000001F4DDED6158>
    ©¸ <proxypool.processors.getter.Getter object at 0x000001F4DC190DA0>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\processors\getter.py", line 36, in run
    for proxy in crawler.crawl():
                 ©¦       ©¸ <function BaseCrawler.crawl at 0x000001F4DDDC76A8>
                 ©¸ <public.66ip.SixIp object at 0x000001F4DE27E2B0>

> File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\crawlers\base.py", line 27, in crawl
    for proxy in self.parse(html):
                 ©¦    ©¦     ©¸ '\r\n<!doctype html public "-//w3c//dtd xhtml 1.0 transitional//en" "http://www.w3.org/tr/xhtml1/dtd/xhtml1-transitional.dtd"...
                 ©¦    ©¸ <function SixIp.parse at 0x000001F4DDED0D90>
                 ©¸ <public.66ip.SixIp object at 0x000001F4DE27E2B0>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\crawlers\public\66ip.py", line 19, in parse
    port = int(tr.find('td:nth-child(2)').text())
               ©¦  ©¸ <function PyQuery.find at 0x000001F4DDEC9D08>
               ©¸ [<table>]

ValueError: invalid literal for int() with base 10: '¶Ë¿ÚºÅ 3128 999 9999 33729 9999 9999 31264 8080 42670 8080 9999'
2020-07-25 20:48:14.711 | ERROR    | proxypool.crawlers.base:crawl:27 - An error has been caught in function 'crawl', process 'Process-2' (2256), thread 'MainThread' (11944):
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "D:\development\Python\lib\multiprocessing\spawn.py", line 105, in spawn_main
    exitcode = _main(fd)
               ©¦     ©¸ 3
               ©¸ <function _main at 0x000001F4DC1AB840>
  File "D:\development\Python\lib\multiprocessing\spawn.py", line 118, in _main
    return self._bootstrap()
           ©¦    ©¸ <function BaseProcess._bootstrap at 0x000001F4DC1968C8>
           ©¸ <Process(Process-2, started)>
  File "D:\development\Python\lib\multiprocessing\process.py", line 258, in _bootstrap
    self.run()
    ©¦    ©¸ <function BaseProcess.run at 0x000001F4DC1960D0>
    ©¸ <Process(Process-2, started)>
  File "D:\development\Python\lib\multiprocessing\process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
    ©¦    ©¦        ©¦    ©¦        ©¦    ©¸ {}
    ©¦    ©¦        ©¦    ©¦        ©¸ <Process(Process-2, started)>
    ©¦    ©¦        ©¦    ©¸ ()
    ©¦    ©¦        ©¸ <Process(Process-2, started)>
    ©¦    ©¸ <bound method Scheduler.run_getter of <proxypool.scheduler.Scheduler object at 0x000001F4DE27E048>>
    ©¸ <Process(Process-2, started)>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\scheduler.py", line 47, in run_getter
    getter.run()
    ©¦      ©¸ <function Getter.run at 0x000001F4DDED6158>
    ©¸ <proxypool.processors.getter.Getter object at 0x000001F4DC190DA0>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\processors\getter.py", line 36, in run
    for proxy in crawler.crawl():
                 ©¦       ©¸ <function BaseCrawler.crawl at 0x000001F4DDDC76A8>
                 ©¸ <public.66ip.SixIp object at 0x000001F4DE27E2B0>

> File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\crawlers\base.py", line 27, in crawl
    for proxy in self.parse(html):
                 ©¦    ©¦     ©¸ '\r\n<!doctype html public "-//w3c//dtd xhtml 1.0 transitional//en" "http://www.w3.org/tr/xhtml1/dtd/xhtml1-transitional.dtd"...
                 ©¦    ©¸ <function SixIp.parse at 0x000001F4DDED0D90>
                 ©¸ <public.66ip.SixIp object at 0x000001F4DE27E2B0>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\crawlers\public\66ip.py", line 19, in parse
    port = int(tr.find('td:nth-child(2)').text())
               ©¦  ©¸ <function PyQuery.find at 0x000001F4DDEC9D08>
               ©¸ [<table>]

ValueError: invalid literal for int() with base 10: '¶Ë¿ÚºÅ 3128 999 9999 33729 9999 9999 31264 8080 42670 8080 9999'
2020-07-25 20:48:14.970 | ERROR    | proxypool.crawlers.base:crawl:27 - An error has been caught in function 'crawl', process 'Process-2' (2256), thread 'MainThread' (11944):
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "D:\development\Python\lib\multiprocessing\spawn.py", line 105, in spawn_main
    exitcode = _main(fd)
               ©¦     ©¸ 3
               ©¸ <function _main at 0x000001F4DC1AB840>
  File "D:\development\Python\lib\multiprocessing\spawn.py", line 118, in _main
    return self._bootstrap()
           ©¦    ©¸ <function BaseProcess._bootstrap at 0x000001F4DC1968C8>
           ©¸ <Process(Process-2, started)>
  File "D:\development\Python\lib\multiprocessing\process.py", line 258, in _bootstrap
    self.run()
    ©¦    ©¸ <function BaseProcess.run at 0x000001F4DC1960D0>
    ©¸ <Process(Process-2, started)>
  File "D:\development\Python\lib\multiprocessing\process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
    ©¦    ©¦        ©¦    ©¦        ©¦    ©¸ {}
    ©¦    ©¦        ©¦    ©¦        ©¸ <Process(Process-2, started)>
    ©¦    ©¦        ©¦    ©¸ ()
    ©¦    ©¦        ©¸ <Process(Process-2, started)>
    ©¦    ©¸ <bound method Scheduler.run_getter of <proxypool.scheduler.Scheduler object at 0x000001F4DE27E048>>
    ©¸ <Process(Process-2, started)>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\scheduler.py", line 47, in run_getter
    getter.run()
    ©¦      ©¸ <function Getter.run at 0x000001F4DDED6158>
    ©¸ <proxypool.processors.getter.Getter object at 0x000001F4DC190DA0>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\processors\getter.py", line 36, in run
    for proxy in crawler.crawl():
                 ©¦       ©¸ <function BaseCrawler.crawl at 0x000001F4DDDC76A8>
                 ©¸ <public.66ip.SixIp object at 0x000001F4DE27E2B0>

> File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\crawlers\base.py", line 27, in crawl
    for proxy in self.parse(html):
                 ©¦    ©¦     ©¸ '\r\n<!doctype html public "-//w3c//dtd xhtml 1.0 transitional//en" "http://www.w3.org/tr/xhtml1/dtd/xhtml1-transitional.dtd"...
                 ©¦    ©¸ <function SixIp.parse at 0x000001F4DDED0D90>
                 ©¸ <public.66ip.SixIp object at 0x000001F4DE27E2B0>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\crawlers\public\66ip.py", line 19, in parse
    port = int(tr.find('td:nth-child(2)').text())
               ©¦  ©¸ <function PyQuery.find at 0x000001F4DDEC9D08>
               ©¸ [<table>]

ValueError: invalid literal for int() with base 10: '¶Ë¿ÚºÅ 3128 36910 8118 8080 61815 9999 5836 8080 5836 8080 8080 8811'
2020-07-25 20:48:15.223 | ERROR    | proxypool.crawlers.base:crawl:27 - An error has been caught in function 'crawl', process 'Process-2' (2256), thread 'MainThread' (11944):
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "D:\development\Python\lib\multiprocessing\spawn.py", line 105, in spawn_main
    exitcode = _main(fd)
               ©¦     ©¸ 3
               ©¸ <function _main at 0x000001F4DC1AB840>
  File "D:\development\Python\lib\multiprocessing\spawn.py", line 118, in _main
    return self._bootstrap()
           ©¦    ©¸ <function BaseProcess._bootstrap at 0x000001F4DC1968C8>
           ©¸ <Process(Process-2, started)>
  File "D:\development\Python\lib\multiprocessing\process.py", line 258, in _bootstrap
    self.run()
    ©¦    ©¸ <function BaseProcess.run at 0x000001F4DC1960D0>
    ©¸ <Process(Process-2, started)>
  File "D:\development\Python\lib\multiprocessing\process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
    ©¦    ©¦        ©¦    ©¦        ©¦    ©¸ {}
    ©¦    ©¦        ©¦    ©¦        ©¸ <Process(Process-2, started)>
    ©¦    ©¦        ©¦    ©¸ ()
    ©¦    ©¦        ©¸ <Process(Process-2, started)>
    ©¦    ©¸ <bound method Scheduler.run_getter of <proxypool.scheduler.Scheduler object at 0x000001F4DE27E048>>
    ©¸ <Process(Process-2, started)>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\scheduler.py", line 47, in run_getter
    getter.run()
    ©¦      ©¸ <function Getter.run at 0x000001F4DDED6158>
    ©¸ <proxypool.processors.getter.Getter object at 0x000001F4DC190DA0>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\processors\getter.py", line 36, in run
    for proxy in crawler.crawl():
                 ©¦       ©¸ <function BaseCrawler.crawl at 0x000001F4DDDC76A8>
                 ©¸ <public.66ip.SixIp object at 0x000001F4DE27E2B0>

> File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\crawlers\base.py", line 27, in crawl
    for proxy in self.parse(html):
                 ©¦    ©¦     ©¸ '\r\n<!doctype html public "-//w3c//dtd xhtml 1.0 transitional//en" "http://www.w3.org/tr/xhtml1/dtd/xhtml1-transitional.dtd"...
                 ©¦    ©¸ <function SixIp.parse at 0x000001F4DDED0D90>
                 ©¸ <public.66ip.SixIp object at 0x000001F4DE27E2B0>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\crawlers\public\66ip.py", line 19, in parse
    port = int(tr.find('td:nth-child(2)').text())
               ©¦  ©¸ <function PyQuery.find at 0x000001F4DDEC9D08>
               ©¸ [<table>]

ValueError: invalid literal for int() with base 10: '¶Ë¿ÚºÅ 9999 9999 18759 8888 40049 9999 5836 8080 3128 60619 38011 8080'
2020-07-25 20:48:15.442 | ERROR    | proxypool.crawlers.base:crawl:27 - An error has been caught in function 'crawl', process 'Process-2' (2256), thread 'MainThread' (11944):
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "D:\development\Python\lib\multiprocessing\spawn.py", line 105, in spawn_main
    exitcode = _main(fd)
               ©¦     ©¸ 3
               ©¸ <function _main at 0x000001F4DC1AB840>
  File "D:\development\Python\lib\multiprocessing\spawn.py", line 118, in _main
    return self._bootstrap()
           ©¦    ©¸ <function BaseProcess._bootstrap at 0x000001F4DC1968C8>
           ©¸ <Process(Process-2, started)>
  File "D:\development\Python\lib\multiprocessing\process.py", line 258, in _bootstrap
    self.run()
    ©¦    ©¸ <function BaseProcess.run at 0x000001F4DC1960D0>
    ©¸ <Process(Process-2, started)>
  File "D:\development\Python\lib\multiprocessing\process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
    ©¦    ©¦        ©¦    ©¦        ©¦    ©¸ {}
    ©¦    ©¦        ©¦    ©¦        ©¸ <Process(Process-2, started)>
    ©¦    ©¦        ©¦    ©¸ ()
    ©¦    ©¦        ©¸ <Process(Process-2, started)>
    ©¦    ©¸ <bound method Scheduler.run_getter of <proxypool.scheduler.Scheduler object at 0x000001F4DE27E048>>
    ©¸ <Process(Process-2, started)>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\scheduler.py", line 47, in run_getter
    getter.run()
    ©¦      ©¸ <function Getter.run at 0x000001F4DDED6158>
    ©¸ <proxypool.processors.getter.Getter object at 0x000001F4DC190DA0>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\processors\getter.py", line 36, in run
    for proxy in crawler.crawl():
                 ©¦       ©¸ <function BaseCrawler.crawl at 0x000001F4DDDC76A8>
                 ©¸ <public.66ip.SixIp object at 0x000001F4DE27E2B0>

> File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\crawlers\base.py", line 27, in crawl
    for proxy in self.parse(html):
                 ©¦    ©¦     ©¸ '\r\n<!doctype html public "-//w3c//dtd xhtml 1.0 transitional//en" "http://www.w3.org/tr/xhtml1/dtd/xhtml1-transitional.dtd"...
                 ©¦    ©¸ <function SixIp.parse at 0x000001F4DDED0D90>
                 ©¸ <public.66ip.SixIp object at 0x000001F4DE27E2B0>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\crawlers\public\66ip.py", line 19, in parse
    port = int(tr.find('td:nth-child(2)').text())
               ©¦  ©¸ <function PyQuery.find at 0x000001F4DDEC9D08>
               ©¸ [<table>]

ValueError: invalid literal for int() with base 10: '¶Ë¿ÚºÅ 9999 5836 8080 34235 80 9999 8080 8123 8080 35101 8080 61574'
2020-07-25 20:48:15.681 | ERROR    | proxypool.crawlers.base:crawl:27 - An error has been caught in function 'crawl', process 'Process-2' (2256), thread 'MainThread' (11944):
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "D:\development\Python\lib\multiprocessing\spawn.py", line 105, in spawn_main
    exitcode = _main(fd)
               ©¦     ©¸ 3
               ©¸ <function _main at 0x000001F4DC1AB840>
  File "D:\development\Python\lib\multiprocessing\spawn.py", line 118, in _main
    return self._bootstrap()
           ©¦    ©¸ <function BaseProcess._bootstrap at 0x000001F4DC1968C8>
           ©¸ <Process(Process-2, started)>
  File "D:\development\Python\lib\multiprocessing\process.py", line 258, in _bootstrap
    self.run()
    ©¦    ©¸ <function BaseProcess.run at 0x000001F4DC1960D0>
    ©¸ <Process(Process-2, started)>
  File "D:\development\Python\lib\multiprocessing\process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
    ©¦    ©¦        ©¦    ©¦        ©¦    ©¸ {}
    ©¦    ©¦        ©¦    ©¦        ©¸ <Process(Process-2, started)>
    ©¦    ©¦        ©¦    ©¸ ()
    ©¦    ©¦        ©¸ <Process(Process-2, started)>
    ©¦    ©¸ <bound method Scheduler.run_getter of <proxypool.scheduler.Scheduler object at 0x000001F4DE27E048>>
    ©¸ <Process(Process-2, started)>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\scheduler.py", line 47, in run_getter
    getter.run()
    ©¦      ©¸ <function Getter.run at 0x000001F4DDED6158>
    ©¸ <proxypool.processors.getter.Getter object at 0x000001F4DC190DA0>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\processors\getter.py", line 36, in run
    for proxy in crawler.crawl():
                 ©¦       ©¸ <function BaseCrawler.crawl at 0x000001F4DDDC76A8>
                 ©¸ <public.66ip.SixIp object at 0x000001F4DE27E2B0>

> File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\crawlers\base.py", line 27, in crawl
    for proxy in self.parse(html):
                 ©¦    ©¦     ©¸ '\r\n<!doctype html public "-//w3c//dtd xhtml 1.0 transitional//en" "http://www.w3.org/tr/xhtml1/dtd/xhtml1-transitional.dtd"...
                 ©¦    ©¸ <function SixIp.parse at 0x000001F4DDED0D90>
                 ©¸ <public.66ip.SixIp object at 0x000001F4DE27E2B0>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\crawlers\public\66ip.py", line 19, in parse
    port = int(tr.find('td:nth-child(2)').text())
               ©¦  ©¸ <function PyQuery.find at 0x000001F4DDEC9D08>
               ©¸ [<table>]

ValueError: invalid literal for int() with base 10: '¶Ë¿ÚºÅ 44975 3128 9999 5836 9999 3128 999 8080 8080 9999 3128 8080'
2020-07-25 20:48:15.923 | ERROR    | proxypool.crawlers.base:crawl:27 - An error has been caught in function 'crawl', process 'Process-2' (2256), thread 'MainThread' (11944):
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "D:\development\Python\lib\multiprocessing\spawn.py", line 105, in spawn_main
    exitcode = _main(fd)
               ©¦     ©¸ 3
               ©¸ <function _main at 0x000001F4DC1AB840>
  File "D:\development\Python\lib\multiprocessing\spawn.py", line 118, in _main
    return self._bootstrap()
           ©¦    ©¸ <function BaseProcess._bootstrap at 0x000001F4DC1968C8>
           ©¸ <Process(Process-2, started)>
  File "D:\development\Python\lib\multiprocessing\process.py", line 258, in _bootstrap
    self.run()
    ©¦    ©¸ <function BaseProcess.run at 0x000001F4DC1960D0>
    ©¸ <Process(Process-2, started)>
  File "D:\development\Python\lib\multiprocessing\process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
    ©¦    ©¦        ©¦    ©¦        ©¦    ©¸ {}
    ©¦    ©¦        ©¦    ©¦        ©¸ <Process(Process-2, started)>
    ©¦    ©¦        ©¦    ©¸ ()
    ©¦    ©¦        ©¸ <Process(Process-2, started)>
    ©¦    ©¸ <bound method Scheduler.run_getter of <proxypool.scheduler.Scheduler object at 0x000001F4DE27E048>>
    ©¸ <Process(Process-2, started)>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\scheduler.py", line 47, in run_getter
    getter.run()
    ©¦      ©¸ <function Getter.run at 0x000001F4DDED6158>
    ©¸ <proxypool.processors.getter.Getter object at 0x000001F4DC190DA0>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\processors\getter.py", line 36, in run
    for proxy in crawler.crawl():
                 ©¦       ©¸ <function BaseCrawler.crawl at 0x000001F4DDDC76A8>
                 ©¸ <public.66ip.SixIp object at 0x000001F4DE27E2B0>

> File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\crawlers\base.py", line 27, in crawl
    for proxy in self.parse(html):
                 ©¦    ©¦     ©¸ '\r\n<!doctype html public "-//w3c//dtd xhtml 1.0 transitional//en" "http://www.w3.org/tr/xhtml1/dtd/xhtml1-transitional.dtd"...
                 ©¦    ©¸ <function SixIp.parse at 0x000001F4DDED0D90>
                 ©¸ <public.66ip.SixIp object at 0x000001F4DE27E2B0>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\crawlers\public\66ip.py", line 19, in parse
    port = int(tr.find('td:nth-child(2)').text())
               ©¦  ©¸ <function PyQuery.find at 0x000001F4DDEC9D08>
               ©¸ [<table>]

ValueError: invalid literal for int() with base 10: '¶Ë¿ÚºÅ 9000 9999 8899 8080 9999 8080 999 44939 9999 20096 53281 8080'
2020-07-25 20:48:16.146 | ERROR    | proxypool.crawlers.base:crawl:27 - An error has been caught in function 'crawl', process 'Process-2' (2256), thread 'MainThread' (11944):
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "D:\development\Python\lib\multiprocessing\spawn.py", line 105, in spawn_main
    exitcode = _main(fd)
               ©¦     ©¸ 3
               ©¸ <function _main at 0x000001F4DC1AB840>
  File "D:\development\Python\lib\multiprocessing\spawn.py", line 118, in _main
    return self._bootstrap()
           ©¦    ©¸ <function BaseProcess._bootstrap at 0x000001F4DC1968C8>
           ©¸ <Process(Process-2, started)>
  File "D:\development\Python\lib\multiprocessing\process.py", line 258, in _bootstrap
    self.run()
    ©¦    ©¸ <function BaseProcess.run at 0x000001F4DC1960D0>
    ©¸ <Process(Process-2, started)>
  File "D:\development\Python\lib\multiprocessing\process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
    ©¦    ©¦        ©¦    ©¦        ©¦    ©¸ {}
    ©¦    ©¦        ©¦    ©¦        ©¸ <Process(Process-2, started)>
    ©¦    ©¦        ©¦    ©¸ ()
    ©¦    ©¦        ©¸ <Process(Process-2, started)>
    ©¦    ©¸ <bound method Scheduler.run_getter of <proxypool.scheduler.Scheduler object at 0x000001F4DE27E048>>
    ©¸ <Process(Process-2, started)>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\scheduler.py", line 47, in run_getter
    getter.run()
    ©¦      ©¸ <function Getter.run at 0x000001F4DDED6158>
    ©¸ <proxypool.processors.getter.Getter object at 0x000001F4DC190DA0>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\processors\getter.py", line 36, in run
    for proxy in crawler.crawl():
                 ©¦       ©¸ <function BaseCrawler.crawl at 0x000001F4DDDC76A8>
                 ©¸ <public.66ip.SixIp object at 0x000001F4DE27E2B0>

> File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\crawlers\base.py", line 27, in crawl
    for proxy in self.parse(html):
                 ©¦    ©¦     ©¸ '\r\n<!doctype html public "-//w3c//dtd xhtml 1.0 transitional//en" "http://www.w3.org/tr/xhtml1/dtd/xhtml1-transitional.dtd"...
                 ©¦    ©¸ <function SixIp.parse at 0x000001F4DDED0D90>
                 ©¸ <public.66ip.SixIp object at 0x000001F4DE27E2B0>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\crawlers\public\66ip.py", line 19, in parse
    port = int(tr.find('td:nth-child(2)').text())
               ©¦  ©¸ <function PyQuery.find at 0x000001F4DDEC9D08>
               ©¸ [<table>]

ValueError: invalid literal for int() with base 10: '¶Ë¿ÚºÅ 9999 5836 8080 36609 55138 8080 9999 8080 999 47687 5836 9991'
2020-07-25 20:48:16.395 | ERROR    | proxypool.crawlers.base:crawl:27 - An error has been caught in function 'crawl', process 'Process-2' (2256), thread 'MainThread' (11944):
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "D:\development\Python\lib\multiprocessing\spawn.py", line 105, in spawn_main
    exitcode = _main(fd)
               ©¦     ©¸ 3
               ©¸ <function _main at 0x000001F4DC1AB840>
  File "D:\development\Python\lib\multiprocessing\spawn.py", line 118, in _main
    return self._bootstrap()
           ©¦    ©¸ <function BaseProcess._bootstrap at 0x000001F4DC1968C8>
           ©¸ <Process(Process-2, started)>
  File "D:\development\Python\lib\multiprocessing\process.py", line 258, in _bootstrap
    self.run()
    ©¦    ©¸ <function BaseProcess.run at 0x000001F4DC1960D0>
    ©¸ <Process(Process-2, started)>
  File "D:\development\Python\lib\multiprocessing\process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
    ©¦    ©¦        ©¦    ©¦        ©¦    ©¸ {}
    ©¦    ©¦        ©¦    ©¦        ©¸ <Process(Process-2, started)>
    ©¦    ©¦        ©¦    ©¸ ()
    ©¦    ©¦        ©¸ <Process(Process-2, started)>
    ©¦    ©¸ <bound method Scheduler.run_getter of <proxypool.scheduler.Scheduler object at 0x000001F4DE27E048>>
    ©¸ <Process(Process-2, started)>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\scheduler.py", line 47, in run_getter
    getter.run()
    ©¦      ©¸ <function Getter.run at 0x000001F4DDED6158>
    ©¸ <proxypool.processors.getter.Getter object at 0x000001F4DC190DA0>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\processors\getter.py", line 36, in run
    for proxy in crawler.crawl():
                 ©¦       ©¸ <function BaseCrawler.crawl at 0x000001F4DDDC76A8>
                 ©¸ <public.66ip.SixIp object at 0x000001F4DE27E2B0>

> File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\crawlers\base.py", line 27, in crawl
    for proxy in self.parse(html):
                 ©¦    ©¦     ©¸ '\r\n<!doctype html public "-//w3c//dtd xhtml 1.0 transitional//en" "http://www.w3.org/tr/xhtml1/dtd/xhtml1-transitional.dtd"...
                 ©¦    ©¸ <function SixIp.parse at 0x000001F4DDED0D90>
                 ©¸ <public.66ip.SixIp object at 0x000001F4DE27E2B0>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\crawlers\public\66ip.py", line 19, in parse
    port = int(tr.find('td:nth-child(2)').text())
               ©¦  ©¸ <function PyQuery.find at 0x000001F4DDEC9D08>
               ©¸ [<table>]

ValueError: invalid literal for int() with base 10: '¶Ë¿ÚºÅ 80 5836 3129 8080 9999 8080 5836 80 20018 53117 8080 23500'
2020-07-25 20:48:24.470 | ERROR    | proxypool.processors.getter:run:36 - An error has been caught in function 'run', process 'Process-2' (2256), thread 'MainThread' (11944):
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "D:\development\Python\lib\multiprocessing\spawn.py", line 105, in spawn_main
    exitcode = _main(fd)
               ©¦     ©¸ 3
               ©¸ <function _main at 0x000001F4DC1AB840>
  File "D:\development\Python\lib\multiprocessing\spawn.py", line 118, in _main
    return self._bootstrap()
           ©¦    ©¸ <function BaseProcess._bootstrap at 0x000001F4DC1968C8>
           ©¸ <Process(Process-2, started)>
  File "D:\development\Python\lib\multiprocessing\process.py", line 258, in _bootstrap
    self.run()
    ©¦    ©¸ <function BaseProcess.run at 0x000001F4DC1960D0>
    ©¸ <Process(Process-2, started)>
  File "D:\development\Python\lib\multiprocessing\process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
    ©¦    ©¦        ©¦    ©¦        ©¦    ©¸ {}
    ©¦    ©¦        ©¦    ©¦        ©¸ <Process(Process-2, started)>
    ©¦    ©¦        ©¦    ©¸ ()
    ©¦    ©¦        ©¸ <Process(Process-2, started)>
    ©¦    ©¸ <bound method Scheduler.run_getter of <proxypool.scheduler.Scheduler object at 0x000001F4DE27E048>>
    ©¸ <Process(Process-2, started)>

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\scheduler.py", line 47, in run_getter
    getter.run()
    ©¦      ©¸ <function Getter.run at 0x000001F4DDED6158>
    ©¸ <proxypool.processors.getter.Getter object at 0x000001F4DC190DA0>

> File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\processors\getter.py", line 36, in run
    for proxy in crawler.crawl():
        ©¦        ©¦       ©¸ <function BaseCrawler.crawl at 0x000001F4DDDC76A8>
        ©¦        ©¸ <public.kuaidaili.KuaidailiCrawler object at 0x000001F4DE27E240>
        ©¸ Proxy(host='117.85.48.26', port='9999')

  File "D:\PythonCoding\pycode\ProxyPool\ProxiesPool\proxypool\crawlers\base.py", line 26, in crawl
    html = self.fetch(url)
    ©¦      ©¦    ©¦     ©¸ 'https://www.kuaidaili.com/free/inha/2/'
    ©¦      ©¦    ©¸ <function BaseCrawler.fetch at 0x000001F4DDDC7620>
    ©¦      ©¸ <public.kuaidaili.KuaidailiCrawler object at 0x000001F4DE27E240>
    ©¸ '<!DOCTYPE html>\n<html>\n<head>\n<meta http-equiv="X-UA-Compatible" content="IE=edge" />\n<meta http-equiv="Content-Type" co...

  File "D:\development\Python\lib\site-packages\retrying.py", line 49, in wrapped_f
    return Retrying(*dargs, **dkw).call(f, *args, **kw)
           ©¦         ©¦        ©¦         ©¦   ©¦       ©¸ {}
           ©¦         ©¦        ©¦         ©¦   ©¸ (<public.kuaidaili.KuaidailiCrawler object at 0x000001F4DE27E240>, 'https://www.kuaidaili.com/free/inha/2/')
           ©¦         ©¦        ©¦         ©¸ <function BaseCrawler.fetch at 0x000001F4DDDC7598>
           ©¦         ©¦        ©¸ {'stop_max_attempt_number': 3, 'retry_on_result': <function BaseCrawler.<lambda> at 0x000001F4DD8D9EA0>}
           ©¦         ©¸ ()
           ©¸ <class 'retrying.Retrying'>
  File "D:\development\Python\lib\site-packages\retrying.py", line 214, in call
    raise RetryError(attempt)
          ©¦          ©¸ Attempts: 3, Value: None
          ©¸ <class 'retrying.RetryError'>

retrying.RetryError: RetryError[Attempts: 3, Value: None]
